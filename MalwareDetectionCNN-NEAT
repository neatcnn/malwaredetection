import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Dropout
import neat

# Load and preprocess the data
data = pd.read_csv(r"dataset-malware.csv")
data['classification'] = data.classification.map({'B': 0, 'S': 1})
data = data.sample(frac=1).reset_index(drop=True)

sns.countplot(data["classification"])

X = data.drop(["Name", "classification"], axis=1)
Y = data["classification"]
x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)

scaler = StandardScaler()
x_train = scaler.fit_transform(x_train)
x_test = scaler.transform(x_test)

input_size = x_train.shape[1]
output_size = 2

# Define the NEAT configuration
config_path = "neat_config_file.txt"  # Create a NEAT configuration file
config = neat.config.Config(neat.DefaultGenome, neat.DefaultReproduction,
                            neat.DefaultSpeciesSet, neat.DefaultStagnation,
                            config_path)

# Define the CNN model creation function
def create_cnn_model(genome):
    model = tf.keras.Sequential([
        Conv1D(256, kernel_size=3, activation='relu', input_shape=(input_size, 1)),
        MaxPooling1D(2),
        Conv1D(128, kernel_size=3, activation='relu', padding='same'),
        MaxPooling1D(2),
        Flatten(),
        Dense(512, activation='relu'),
        Dropout(0.2),
        Dense(output_size, activation='softmax')
    ])
    
    model.compile(optimizer='RMSprop', loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    model.set_weights(genome_to_weights(genome))

    return model

# Define the fitness function
def evaluate_genome(genome, config):
    cnn_model = create_cnn_model(genome)

    # Flatten the input data for NEAT
    flattened_x_train = x_train.reshape(x_train.shape[0], -1)

    cnn_model.fit(x_train, y_train, epochs=5, validation_data=(x_test, y_test), verbose=0)

    # Evaluate the model and return the fitness (accuracy, for example)
    _, accuracy = cnn_model.evaluate(x_test, y_test, verbose=0)
    genome.fitness = accuracy

# Function to convert NEAT genome to model weights
def genome_to_weights(genome):
    return [connection.weight for connection in genome.connections.values() if connection.enabled]


# Create the NEAT population
p = neat.Population(config)

best = None

# Update the best genome
for g in p.population.values():
    if best is None or (g.fitness is not None and g.fitness > best.fitness):
        #print('\nTest accuracy: {0:.6f}'.format(g.fitness))
        best = g

# Run the NEAT evolution
p.run(evaluate_genome, 10)  # Adjust the number of generations

# Extract the best genome
best_genome = p.best_genome

# Create the CNN model using the best genome
best_cnn_model = create_cnn_model(best_genome)

# Flatten the test data for evaluation
flattened_x_test = x_test.reshape(x_test.shape[0], -1)

# Evaluate the CNN model on the test set
test_loss, test_accuracy = best_cnn_model.evaluate(flattened_x_test, y_test)

print('\nTest loss: {0:.6f}. Test accuracy: {1:.6f}%'.format(test_loss, test_accuracy * 100.))
